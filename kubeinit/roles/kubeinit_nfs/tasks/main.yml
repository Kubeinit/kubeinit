---
# Copyright 2020 KubeInit.
# All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may
# not use this file except in compliance with the License. You may obtain
# a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.


# "kubeinit_nfs" will search for and load any operating system variable file

# found within the "vars/" path. If no OS files are found the task will skip.
- name: Gather variables for each operating system
  include_vars: "{{ item }}"
  with_first_found:
    - skip: true
      files:
        - "{{ ansible_distribution | lower }}-{{ ansible_distribution_version | lower }}.yml"
        - "{{ ansible_distribution | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
        - "{{ ansible_os_family | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
        - "{{ ansible_distribution | lower }}.yml"
        - "{{ ansible_os_family | lower }}-{{ ansible_distribution_version.split('.')[0] }}.yml"
        - "{{ ansible_os_family | lower }}.yml"
  tags:
    - always

- name: Install NFS packages
  package:
    name: "{{ kubeinit_nfs_packages }}"
    state: present


- name: "configure NFS shares of CentOS based guests"
  shell: |
    set -o pipefail
    systemctl enable nfs-server rpcbind
    systemctl start nfs-server rpcbind
    mkdir -p /var/nfsshare
    chmod -R 777 /var/nfsshare
    chown -R nobody:nobody /var/nfsshare
    echo '/var/nfsshare {{ kubeinit_inventory_network_net }}/{{ kubeinit_inventory_network_cidr }}(rw,sync,no_root_squash,no_all_squash,no_wdelay)' | tee /etc/exports
    setsebool -P nfs_export_all_rw 1
    systemctl restart nfs-server
  register: nfs_share_config
  changed_when: "nfs_share_config.rc == 0"
  when: kubeinit_inventory_cluster_distro == 'okd' or kubeinit_inventory_cluster_distro == 'k8s' or kubeinit_inventory_cluster_distro == 'eks'
  args:
    executable: /bin/bash

- name: "configure NFS shares of Ubuntu based guests"
  shell: |
    set -o pipefail
    mkdir -p /var/nfsshare
    chmod -R 777 /var/nfsshare
    chown -R nobody:nogroup /var/nfsshare
    echo '/var/nfsshare {{ kubeinit_inventory_network_net }}/{{ kubeinit_inventory_network_cidr }}(rw,sync,no_root_squash,no_all_squash,no_wdelay)' | tee /etc/exports
    exportfs -a
    systemctl restart nfs-kernel-server
  register: nfs_share_config
  changed_when: "nfs_share_config.rc == 0"
  when: kubeinit_inventory_cluster_distro == 'rke' or kubeinit_inventory_cluster_distro == 'cdk'
  args:
    executable: /bin/bash

#
# Configure PV
#
- name: "Add some example PV and claims"
  shell: |
    # We create the folder for the PV in our NFS share
    # mkdir -p /var/nfsshare/registry
    # chmod -R 777 /var/nfsshare/registry
    # chown -R nobody:nobody /var/nfsshare/registry
    cat << EOF > ~/registry_pv.yaml
    apiVersion: v1
    kind: PersistentVolume
    metadata:
      name: image-registry-pv
    spec:
      capacity:
        storage: 5Gi
      accessModes:
        - ReadWriteMany
      storageClassName: nfs01registry
      persistentVolumeReclaimPolicy: Retain
      nfs:
        path: /var/nfsshare/registry
        server: {{ hostvars[groups['okd_service_nodes'][0]].ansible_host }}
    EOF
    cat << EOF > ~/registry_pvc.yaml
      apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: image-registry-pvc
      spec:
      volumeName: image-registry-pv
        accessModes:
          - ReadWriteMany
        resources:
          requests:
            storage: 5Gi
        storageClassName: nfs01registry
        volumeMode: Filesystem
    EOF
    # export KUBECONFIG=~/install_dir/auth/kubeconfig
    # oc create -f ~/registry_pv.yaml
    # oc create -f ~/registry_pvc.yaml
    # We patch the imageregistry operator to use
    # the recently created PV by assigning a managed PVC
    # oc patch configs.imageregistry.operator.openshift.io cluster --type merge --patch '{"spec":{"managementState":"Managed"}}'
    # oc patch configs.imageregistry.operator.openshift.io cluster --type merge --patch '{"spec":{"storage":{"pvc":{"claim":"image-registry-pvc"}}}}'
  register: configure_cluster_pv
  changed_when: "configure_cluster_pv.rc == 0"
  delegate_to: "{{ cluster_node }}"
  with_items: "{{ groups['okd_service_nodes'] }}"
  loop_control:
    loop_var: cluster_node
  ignore_errors: yes
  tags:
    - provision_libvirt

#
# add nfs dynamic provisioning
#
- name: add security context constraint for nfs provisioner
  shell: |
    cat << EOF > ~/nfs-scc.yaml
    apiVersion: security.openshift.io/v1
    kind: SecurityContextConstraints
    metadata:
      name: nfs-provisioner
    allowHostDirVolumePlugin: true
    allowHostIPC: false
    allowHostNetwork: false
    allowHostPID: false
    allowHostPorts: false
    allowPrivilegedContainer: false
    allowedCapabilities:
    - DAC_READ_SEARCH
    - SYS_RESOURCE
    defaultAddCapabilities: null
    fsGroup:
      type: MustRunAs
    priority: null
    readOnlyRootFilesystem: false
    requiredDropCapabilities:
    - KILL
    - MKNOD
    - SYS_CHROOT
    runAsUser:
      type: RunAsAny
    seLinuxContext:
      type: MustRunAs
    supplementalGroups:
      type: RunAsAny
    volumes:
    - configMap
    - downwardAPI
    - emptyDir
    - hostPath
    - nfs
    - persistentVolumeClaim
    - secret
    EOF
    export KUBECONFIG=~/install_dir/auth/kubeconfig
    oc create -f ~/nfs-scc.yaml
  tags:
    - provision_libvirt

- name: add nfs provisioning role
  shell: |
    cat << EOF > ~/nfs-rbac.yaml
    kind: ServiceAccount
    apiVersion: v1
    metadata:
      name: nfs-client-provisioner
    ---
    kind: ClusterRole
    apiVersion: rbac.authorization.k8s.io/v1
    metadata:
      name: nfs-client-provisioner-runner
    rules:
      - apiGroups: [""]
        resources: ["persistentvolumes"]
        verbs: ["get", "list", "watch", "create", "delete"]
      - apiGroups: [""]
        resources: ["persistentvolumeclaims"]
        verbs: ["get", "list", "watch", "update"]
      - apiGroups: ["storage.k8s.io"]
        resources: ["storageclasses"]
        verbs: ["get", "list", "watch"]
      - apiGroups: [""]
        resources: ["events"]
        verbs: ["create", "update", "patch"]
    ---
    kind: ClusterRoleBinding
    apiVersion: rbac.authorization.k8s.io/v1
    metadata:
      name: run-nfs-client-provisioner
    subjects:
      - kind: ServiceAccount
        name: nfs-client-provisioner
        namespace: nfs-client-provisioning
    roleRef:
      kind: ClusterRole
      name: nfs-client-provisioner-runner
      apiGroup: rbac.authorization.k8s.io
    ---
    kind: Role
    apiVersion: rbac.authorization.k8s.io/v1
    metadata:
      name: leader-locking-nfs-client-provisioner
    rules:
      - apiGroups: [""]
        resources: ["endpoints"]
        verbs: ["get", "list", "watch", "create", "update", "patch"]
    ---
    kind: RoleBinding
    apiVersion: rbac.authorization.k8s.io/v1
    metadata:
      name: leader-locking-nfs-client-provisioner
    subjects:
      - kind: ServiceAccount
        name: nfs-client-provisioner
        # replace with namespace where provisioner is deployed
        namespace: nfs-client-provisioning
    roleRef:
      kind: Role
      name: leader-locking-nfs-client-provisioner
      apiGroup: rbac.authorization.k8s.io
    EOF
    export KUBECONFIG=~/install_dir/auth/kubeconfig
    oc create -f ~/nfs-rbac.yaml
  tags:
    - provision_libvirt

- name: add nfs client provisioner deployment
  shell: |
    cat << EOF > ~/nfs-client-prov-deployment.yaml
    kind: Deployment
    apiVersion: apps/v1
    metadata:
      name: nfs-client-provisioner
    spec:
      replicas: 1
      strategy:
        type: Recreate
      selector:
        matchLabels:
          app: nfs-client-provisioner
      template:
        metadata:
          labels:
            app: nfs-client-provisioner
        spec:
          serviceAccountName: nfs-client-provisioner
          containers:
            - name: nfs-client-provisioner
              image: quay.io/external_storage/nfs-client-provisioner:latest
              volumeMounts:
                - name: nfs-client-root
                  mountPath: /persistentvolumes
              env:
                - name: PROVISIONER_NAME
                  value: nfs-client-provisioner
                - name: NFS_SERVER
                  value: 10.0.0.100
                - name: NFS_PATH
                  value: /var/nfsshare
          volumes:
            - name: nfs-client-root
              nfs:
                server: 10.0.0.100
                path: /var/nfsshare
    EOF
    export KUBECONFIG=~/install_dir/auth/kubeconfig
    oc create -f ~/nfs-client-prov-deployment.yaml
  tags:
    - provision_libvirt

- name: add default nfs storage class
  shell: |
    cat << EOF > ~/nfs-storage-class.yaml
    apiVersion: storage.k8s.io/v1
    kind: StorageClass
    metadata:
      name: managed-nfs-storage
      annotations:
        storageclass.kubernetes.io/is-default-class: "true"
    provisioner: nfs-client-provisioner
    parameters:
      archiveOnDelete: "false"
    EOF
    export KUBECONFIG=~/install_dir/auth/kubeconfig
    oc create -f ~/nfs-storage-class.yaml
  tags:
    - provision_libvirt

- name: apply nfs security policy to nfs user
  shell: |
    export KUBECONFIG=~/install_dir/auth/kubeconfig
    oc adm policy add-scc-to-user nfs-provisioner -z nfs-client-provisioner
  tags:
    - provision_libvirt
