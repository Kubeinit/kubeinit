<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Usage &mdash; KubeInit  documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/custom.css" type="text/css" />
    <link rel="shortcut icon" href="_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js?v=5d32c60e"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="_static/documentation_options.js?v=5929fcd5"></script>
        <script src="_static/doctools.js?v=888ff710"></script>
        <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Architecture" href="architecture.html" />
    <link rel="prev" title="Welcome to KubeInit’s documentation!" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >


  <a href="http://docs.kubeinit.org/#" class="icon icon-home"> KubeInit



</a>




<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>


        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Usage</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#requirements">Requirements</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#installing-dependencies">Installing dependencies</a></li>
<li class="toctree-l3"><a class="reference internal" href="#multiple-hypervisors-support">Multiple hypervisors support</a></li>
<li class="toctree-l3"><a class="reference internal" href="#kubeinit-spec">Kubeinit spec</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#deployment">Deployment</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#group-variables">Group variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#all">All</a></li>
<li class="toctree-l4"><a class="reference internal" href="#cluster">Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="#defaults">Defaults</a></li>
<li class="toctree-l4"><a class="reference internal" href="#environment">Environment</a></li>
<li class="toctree-l4"><a class="reference internal" href="#network">Network</a></li>
<li class="toctree-l4"><a class="reference internal" href="#secrets">Secrets</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#inventory">Inventory</a></li>
<li class="toctree-l3"><a class="reference internal" href="#directly-executing-the-deployment-playbook">Directly executing the deployment playbook</a></li>
<li class="toctree-l3"><a class="reference internal" href="#running-the-deployment-command-from-a-container">Running the deployment command from a container</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#running-from-the-git-repository">Running from the GIT repository</a></li>
<li class="toctree-l4"><a class="reference internal" href="#running-from-a-release">Running from a release</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#connecting-to-the-cluster">Connecting to the cluster</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#accessing-the-cluster-resources-internally">Accessing the cluster resources internally</a></li>
<li class="toctree-l4"><a class="reference internal" href="#accessing-the-cluster-resources-externally">Accessing the cluster resources externally</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#cleaning-up-the-environment">Cleaning up the environment</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="roles.html">Documented roles in KubeInit</a></li>
<li class="toctree-l1"><a class="reference internal" href="modules.html">Documented modules in KubeInit</a></li>
<li class="toctree-l1"><a class="reference internal" href="howtos_and_presentations.html">HowTo’s and presentations</a></li>
<li class="toctree-l1"><a class="reference internal" href="inventory_diagrams.html">Inventory diagrams</a></li>
<li class="toctree-l1"><a class="reference internal" href="playbook_diagrams.html">Playbook diagrams</a></li>
<li class="toctree-l1"><a class="reference internal" href="supporters.html">Supporters</a></li>
<li class="toctree-l1"><a class="reference internal" href="changelog.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="notice.html">Notice</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">KubeInit</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Usage</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/kubeinit/kubeinit/blob/main/docs/src/usage.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="usage">
<h1>Usage<a class="headerlink" href="#usage" title="Link to this heading"></a></h1>
<p>KubeInit is an Ansible collection, to use it
the only installation requirement is to have Python 3
and Ansible +2.9.</p>
<p>There are two ways of launching KubeInit, directly using the
ansible-playbook command from the project’s source code,
or by running it inside a container.</p>
<section id="requirements">
<h2>Requirements<a class="headerlink" href="#requirements" title="Link to this heading"></a></h2>
<ul class="simple">
<li><p>A fresh deployed server with enough RAM and disk space (120GB in RAM and 300GB in disk) and CentOS 8 (it should work also in Fedora/Debian/Ubuntu hosts).</p></li>
<li><p>We assume that the hypervisor node is called nyctea (defined in the inventory).</p></li>
<li><p>Have root passwordless access with certificates.</p></li>
<li><p>Adjust the inventory file to suit your needs.</p></li>
<li><p>Having podman installed in the machine where you are running ansible-playbook.</p></li>
</ul>
<section id="installing-dependencies">
<h3>Installing dependencies<a class="headerlink" href="#installing-dependencies" title="Link to this heading"></a></h3>
<p>KubeInit calls additional Ansible collections that needs to be installed.
If there are dependencies issues when executing the collection, install
them by executing:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">git clone https://github.com/Kubeinit/kubeinit.git</span>
<span class="go">cd kubeinit</span>
<span class="go">ansible-galaxy collection install --force --requirements-file kubeinit/requirements.yml</span>
</pre></div>
</div>
<p>An example of a possible dependency issue is the following:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">TASK [Configure the cluster service node] ***************************************************************************************************************</span>
<span class="go">ERROR! couldn&#39;t resolve module/action &#39;community.general.docker_login&#39;. This often indicates a misspelling, missing collection, or incorrect module path.</span>
</pre></div>
</div>
<p>By default the KubeInit’s container image installs these requirements, this should only affect
those executing directly the collection from the source code.</p>
<p>There is also needed to build and install the collection if its used directly from the
repository.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp"># </span>From<span class="w"> </span>the<span class="w"> </span>root<span class="w"> </span>directory<span class="w"> </span><span class="k">in</span><span class="w"> </span>the<span class="w"> </span>repository,<span class="w"> </span>execute:
<span class="go">rm -rf ~/.ansible/collections/ansible_collections/kubeinit/kubeinit</span>
<span class="go">ansible-galaxy collection build kubeinit --verbose --force --output-path releases/</span>
<span class="go">ansible-galaxy collection install --force --force-with-deps releases/kubeinit-kubeinit-`cat kubeinit/galaxy.yml | shyaml get-value version`.tar.gz</span>
</pre></div>
</div>
</section>
<section id="multiple-hypervisors-support">
<h3>Multiple hypervisors support<a class="headerlink" href="#multiple-hypervisors-support" title="Link to this heading"></a></h3>
<p>Currently, it is supported the deployment of multiple Kubernetes clusters
in multiple hosts. While it is supported to deploy different Kubernetes distributions
based in different guest OS, for example Vanilla Kubernetes that is based in CentOS and
OKD based in Fedora CoreOS the operative system of the hosts must be the same, this means
to have 3 hypervisors (chassis) based in Debian that will host any of the currently supported
distribution.</p>
<p><strong>Any deployment based on mixed versions of the Hypervisors OS is not supported.</strong>
This is motivated on the potential failures due to mismatch in OVS/OVN and Kernel
versions.</p>
</section>
<section id="kubeinit-spec">
<h3>Kubeinit spec<a class="headerlink" href="#kubeinit-spec" title="Link to this heading"></a></h3>
<p>Currently the inventory to deploy the clusters is dynamic,
this means that it is configured based on the variables that are
passed to the deployment command.
The first hypervisor is denoted also as the bastion host or ‡.</p>
<p>In particular the <cite>kubeinit_spec</cite> variable will determine the
amount of controller nodes, compute nodes, and hypervisors that
will be used.</p>
<p>The current supported syntax of this variable is:</p>
<p><cite>&lt;distro&gt;-&lt;driver&gt;-&lt;controllers&gt;-&lt;computes&gt;-&lt;hypervisors&gt;</cite></p>
<p>For example, combinations like okd-libvirt-1-2-1, k8s-libvirt-3-1-1,
eks-libvirt-1-0-1 are all valid.</p>
</section>
</section>
<section id="deployment">
<h2>Deployment<a class="headerlink" href="#deployment" title="Link to this heading"></a></h2>
<section id="group-variables">
<h3>Group variables<a class="headerlink" href="#group-variables" title="Link to this heading"></a></h3>
<section id="all">
<h4>All<a class="headerlink" href="#all" title="Link to this heading"></a></h4>
<p>Default variables related to Ansible parameters, common
across all the supported scenarios.</p>
<dl class="simple">
<dt>ansible_python_interpreter</dt><dd><p>Specify the Python interpreter.</p>
</dd>
<dt>ansible_ssh_pipelining</dt><dd><p>Enable SSH pipelining.</p>
</dd>
<dt>ansible_ssh_common_args</dt><dd><p>Define the default SSH common arguments.</p>
</dd>
<dt>ansible_debug_enabled</dt><dd><p>Determine if Ansible debug is currently enabled.</p>
</dd>
<dt>ansible_ssh_retries</dt><dd><p>Number of attempts to connect.
Ansible retries connections only if it gets an SSH error with a return code of 255.
Any errors with return codes other than 255 indicate an issue with program execution.</p>
</dd>
</dl>
</section>
<section id="cluster">
<h4>Cluster<a class="headerlink" href="#cluster" title="Link to this heading"></a></h4>
<p>Initial configuration variables related to the cluster parameters.</p>
<dl class="simple">
<dt>cluster_name_docsplaceholder</dt><dd><p>The default for the cluster name is {{ kubeinit_cluster_distro + ‘cluster’ }}
You can override this by setting a specific value for cluster_name in the
kubeinit_cluster_spec command line variable, e.g.
-e kubeinit_cluster_spec=’{“cluster_name”:”mycluster”}’</p>
</dd>
<dt>cluster_domain</dt><dd><p>The default for the cluster domain name</p>
</dd>
<dt>hypervisor_name_pattern</dt><dd><p>The default for the hypervisor naming pattern</p>
</dd>
<dt>controller_name_pattern</dt><dd><p>The default for the controller naming pattern</p>
</dd>
<dt>compute_name_pattern</dt><dd><p>The default for the compute naming pattern</p>
</dd>
</dl>
</section>
<section id="defaults">
<h4>Defaults<a class="headerlink" href="#defaults" title="Link to this heading"></a></h4>
<p>Default variables related to general cluster parameters.</p>
<dl>
<dt>default_network_name</dt><dd><p>The default name we will use for the network</p>
</dd>
<dt>cluster_node_configurations_docsplaceholder</dt><dd><p>Default values for cluster node configuration.</p>
</dd>
<dt>default_cluster_nodes_map_list</dt><dd><p>The following list of maps will be used to build the inventory
of cluster nodes needed by the kubeinit_spec.  Additional
specifications provided on the command line can be used to override
any of these defaults, e.g.</p>
<blockquote>
<div><p>-e cluster_nodes_spec=’[{“when_group”:”controller_nodes”,”disk”=”35G”}]’</p>
</div></blockquote>
</dd>
<dt>default_extra_nodes_map_list</dt><dd><p>Additional specifications provided on the command line can be used to
override any of these defaults, e.g.</p>
<blockquote>
<div><p>-e extra_nodes_spec=’[{“name”:”nova-compute”,”when_distro”:[“okd”],”os”:”centos”}]’</p>
</div></blockquote>
</dd>
<dt>default_service_nodes_map_list</dt><dd><p>Additional specifications provided on the command line can be used to override
any of these defaults, e.g.</p>
<blockquote>
<div><p>-e service_nodes_spec=’[{“services”:[“apache”,”bind”,”dnsmasq”]}]’</p>
</div></blockquote>
</dd>
</dl>
</section>
<section id="environment">
<h4>Environment<a class="headerlink" href="#environment" title="Link to this heading"></a></h4>
<p>The following environment specific variables can be used
with the deployment command.
These variables might be specific to each scenario.</p>
<dl class="simple">
<dt>certificate_country</dt><dd><p>Certificate default country.</p>
</dd>
<dt>certificate_state</dt><dd><p>Certificate default state.</p>
</dd>
<dt>certificate_locality</dt><dd><p>Certificate default locality.</p>
</dd>
<dt>certificate_organization</dt><dd><p>Certificate default organization.</p>
</dd>
<dt>certificate_organizational_unit</dt><dd><p>Certificate default OU.</p>
</dd>
<dt>dns_public</dt><dd><p>Default public DNS.</p>
</dd>
<dt>ssh_keytype</dt><dd><p>Default SSH key type.</p>
</dd>
</dl>
</section>
<section id="network">
<h4>Network<a class="headerlink" href="#network" title="Link to this heading"></a></h4>
<p>General deployment network parameters.</p>
<dl>
<dt>network_name_docsplaceholder</dt><dd><p>The default for the cluster network name is kimgtnet0.</p>
<p>You can override this by setting a specific value for network_name in the
kubeinit_network_spec command line variable, e.g.
-e kubeinit_network_spec=’{“network_name”:”mynetwork”}’</p>
<p>The network name will be used to create a libvirt network for the cluster
guest vms. The network cidr will set the range of addresses reserved for
the cluster nodes. The gateway offset will be used to select the gateway
address within the range, a negative offset starts at the end of the range,
so for network=10.0.0.0/24, gateway_offset=-2 will select 10.0.0.254 and
gateway_offset=1 will select 10.0.0.1 as the address. The other offset
attributes follow the same convention.</p>
</dd>
<dt>network</dt><dd><p>The default for the network CIDR</p>
</dd>
<dt>gateway_offset</dt><dd><p>The default for the gateway offset</p>
</dd>
<dt>dhcp_start_offset</dt><dd><p>The default for the DHCP start lease offset</p>
</dd>
<dt>dhcp_end_offset</dt><dd><p>The default for the DHCP end lease offset</p>
</dd>
</dl>
</section>
<section id="secrets">
<h4>Secrets<a class="headerlink" href="#secrets" title="Link to this heading"></a></h4>
<p>The common secrets supported across all the scenarios
are handled using the following variables.</p>
<dl>
<dt>kubeinit_secrets_secret</dt><dd><dl class="simple">
<p>This variable contains,
a secret placeholder.</p>
<dt>secret_name</dt><dd><p>The secret name represents
a secret placeholder.</p>
</dd>
<dt>envvar_name</dt><dd><p>The envvar name works for
a secret placeholder.</p>
</dd>
</dl>
</dd>
<dt>kubeinit_secrets</dt><dd><p>All the secrets will enable
the deployment capabilities, this is
a docs placeholder.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">kubeinit_secrets</span><span class="p">:</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">secret_name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">This is the secret name.</span>
<span class="w">    </span><span class="nt">dict_varname</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Where we will store the secret.</span>
<span class="w">    </span><span class="nt">dict_key</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">The secret value.</span>
<span class="w">    </span><span class="nt">env_varname</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">A default value from an environmental variable.</span>
</pre></div>
</div>
<p>The ones that are currently used:</p>
<ul class="simple">
<li><p>kubeinit-ssh-key: Docs placeholder.</p></li>
<li><p>dockerhub-username: Docs placeholder.</p></li>
<li><p>dockerhub-password: Docs placeholder.</p></li>
<li><p>openshift-pullsecret: Docs placeholder.</p></li>
</ul>
</dd>
</dl>
</section>
</section>
<section id="inventory">
<h3>Inventory<a class="headerlink" href="#inventory" title="Link to this heading"></a></h3>
<p>The following einventory structure must be followed.</p>
</section>
<section id="directly-executing-the-deployment-playbook">
<h3>Directly executing the deployment playbook<a class="headerlink" href="#directly-executing-the-deployment-playbook" title="Link to this heading"></a></h3>
<p>The following example command will deploy a multi-master OKD 4.5 cluster with 1 worker node
in a single command and in approximately 30 minutes.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">git clone https://github.com/Kubeinit/kubeinit.git</span>
<span class="go">cd kubeinit</span>
<span class="go">ansible-playbook \</span>
<span class="go">    -v --user root \</span>
<span class="go">    -e kubeinit_spec=okd-libvirt-3-2-1 \</span>
<span class="go">    -i ./kubeinit/inventory.yml \</span>
<span class="go">    ./kubeinit/playbook.yml</span>
</pre></div>
</div>
<p>After provisioning any of the scenarios, you should have your environment ready to go.
To connect to the nodes from the hypervisor use the IP addresses from the inventory files.</p>
</section>
<section id="running-the-deployment-command-from-a-container">
<h3>Running the deployment command from a container<a class="headerlink" href="#running-the-deployment-command-from-a-container" title="Link to this heading"></a></h3>
<p>The whole process is explained in the <a class="reference external" href="https://www.anstack.com/blog/2020/09/11/Deploying-KubeInit-from-a-container.html">HowTo’s</a>.
The following commands build a container image with the project inside of it, and then
launches the container executing the ansible-playbook command with all the
standard ansible-playbook parameters.</p>
<p>Note: When running the deployment from a container,
<cite>nyctea</cite> can not be 127.0.0.1, it needs to be
the hypervisor’s IP address. Also when running the
deployment as a user different than root, the
keys needs to be also updated.</p>
<section id="running-from-the-git-repository">
<h4>Running from the GIT repository<a class="headerlink" href="#running-from-the-git-repository" title="Link to this heading"></a></h4>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">git clone https://github.com/Kubeinit/kubeinit.git</span>
<span class="go">cd kubeinit</span>
<span class="go">podman build -t kubeinit/kubeinit .</span>
<span class="go">podman run --rm -it \</span>
<span class="go">    -v ~/.ssh/id_rsa:/root/.ssh/id_rsa:z \</span>
<span class="go">    -v ~/.ssh/id_rsa.pub:/root/.ssh/id_rsa.pub:z \</span>
<span class="go">    -v ~/.ssh/config:/root/.ssh/config:z \</span>
<span class="go">    kubeinit/kubeinit \</span>
<span class="go">        -v --user root \</span>
<span class="go">        -e kubeinit_spec=okd-libvirt-3-2-1 \</span>
<span class="go">        -i ./kubeinit/inventory.yml \</span>
<span class="go">        ./kubeinit/playbook.yml</span>
</pre></div>
</div>
</section>
<section id="running-from-a-release">
<h4>Running from a release<a class="headerlink" href="#running-from-a-release" title="Link to this heading"></a></h4>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp"># </span>Get<span class="w"> </span>the<span class="w"> </span>latest<span class="w"> </span>release<span class="w"> </span>tag
<span class="go">TAG=$(curl --silent &quot;https://api.github.com/repos/kubeinit/kubeinit/releases/latest&quot; | jq -r .tag_name)</span>
<span class="go">podman run --rm -it \</span>
<span class="go">    -v ~/.ssh/id_rsa:/root/.ssh/id_rsa:z \</span>
<span class="go">    -v ~/.ssh/id_rsa.pub:/root/.ssh/id_rsa.pub:z \</span>
<span class="go">    -v ~/.ssh/config:/root/.ssh/config:z \</span>
<span class="go">    quay.io/kubeinit/kubeinit:$TAG \</span>
<span class="go">        -v --user root \</span>
<span class="go">        -e kubeinit_spec=okd-libvirt-3-2-1 \</span>
<span class="go">        -i ./kubeinit/inventory.yml \</span>
<span class="go">        ./kubeinit/playbook.yml</span>
</pre></div>
</div>
</section>
</section>
<section id="connecting-to-the-cluster">
<h3>Connecting to the cluster<a class="headerlink" href="#connecting-to-the-cluster" title="Link to this heading"></a></h3>
<section id="accessing-the-cluster-resources-internally">
<h4>Accessing the cluster resources internally<a class="headerlink" href="#accessing-the-cluster-resources-internally" title="Link to this heading"></a></h4>
<p>Once the deployment is finished the machine used
for provisioning the cluster have access to both
the pod services and instances created.
The SSH keys are stored in the .ssh folder from the
home folder of the user triggering the deployment.
For instance:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp"># </span>From<span class="w"> </span>the<span class="w"> </span>hypervisor<span class="w"> </span>node<span class="w"> </span>the<span class="w"> </span>user<span class="w"> </span>should
<span class="gp"># </span>have<span class="w"> </span>passwordless<span class="w"> </span>access<span class="w"> </span>to<span class="w"> </span>the<span class="w"> </span>services<span class="w"> </span>pod
<span class="gp">root@mocoloco kubeinit]# </span>ssh<span class="w"> </span>-i<span class="w"> </span>~/.ssh/rkecluster_id_rsa<span class="w"> </span>root@10.0.0.253
<span class="go">Welcome to Ubuntu 20.10 (GNU/Linux 5.8.0-53-generic x86_64)</span>
<span class="go">  System load:  0.0                Users logged in:               0</span>
<span class="go">  Usage of /:   2.5% of 147.34GB   IPv4 address for docker0:      172.17.0.1</span>
<span class="go">  Memory usage: 4%                 IPv4 address for enp1s0:       10.0.0.253</span>
<span class="go">  Swap usage:   0%                 IPv4 address for vetha0e3a877: 172.16.16.1</span>
<span class="go">  Processes:    186</span>

<span class="gp"># </span>Get<span class="w"> </span>the<span class="w"> </span>cluster<span class="w"> </span>nodes
<span class="gp">root@rke-service-01:~# </span>kubectl<span class="w"> </span>get<span class="w"> </span>nodes
<span class="go">NAME            STATUS   ROLES               AGE   VERSION</span>
<span class="go">rke-controller-01   Ready    controlplane,etcd   11m   v1.19.3</span>

<span class="gp"># </span>In<span class="w"> </span>the<span class="w"> </span>root<span class="w"> </span>folder<span class="w"> </span>there<span class="w"> </span>are<span class="w"> </span>files<span class="w"> </span>with<span class="w"> </span>some<span class="w"> </span>details<span class="w"> </span>about<span class="w"> </span>the<span class="w"> </span>deployment
<span class="gp"># </span>like<span class="w"> </span>the<span class="w"> </span>kubeconfig<span class="w"> </span>file,<span class="w"> </span>the<span class="w"> </span>container<span class="w"> </span>images<span class="w"> </span>used<span class="w"> </span><span class="k">in</span><span class="w"> </span>the<span class="w"> </span>deployment,
<span class="gp"># </span>and<span class="w"> </span>the<span class="w"> </span>registry<span class="w"> </span>pull<span class="w"> </span>secret.
<span class="gp">root@rke-service-01:~# </span>ls
<span class="go">cluster.rkestate  httpd.conf               kubeinit_deployment_images.txt  pullsecret.json      rke           snap</span>
<span class="go">cluster.yml       kube_config_cluster.yml  pod_cidr                        registry-auths.json  service_cidr</span>

<span class="gp"># </span>The<span class="w"> </span>cluster<span class="w"> </span>config<span class="w"> </span>file<span class="w"> </span>is<span class="w"> </span>also<span class="w"> </span>copied<span class="w"> </span>to<span class="w"> </span>the<span class="w"> </span>default<span class="w"> </span>folder.
<span class="gp">root@rke-service-01:~# </span>ls<span class="w"> </span>.kube/config
<span class="go">.kube/config</span>
</pre></div>
</div>
</section>
<section id="accessing-the-cluster-resources-externally">
<h4>Accessing the cluster resources externally<a class="headerlink" href="#accessing-the-cluster-resources-externally" title="Link to this heading"></a></h4>
<p>When the services deployment is executed
one of the tasks in the kubeinit_bind role
will create an external ingress script on the primary
(bastion) hypervisor called create-external-ingress.sh.</p>
<p>Running that script will create the required tunnels
for all the service endpoints on the cluster.</p>
<p>A user should be able to fetch the kubeadmin password running a command like:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">echo $(ssh root@nyctea ssh root@10.0.0.100 cat install_dir/auth/kubeadmin-password)</span>
</pre></div>
</div>
<p>The console should be available at
<a class="reference external" href="https://console-openshift-console.apps.okdcluster.kubeinit.local">https://console-openshift-console.apps.okdcluster.kubeinit.local</a>
from the external machine if you have a similar configuration in the
<cite>/etc/resolv.conf</cite>.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">search okdcluster.kubeinit.local</span>
<span class="go">nameserver &lt;ip of nyctea&gt;</span>
<span class="go">nameserver 8.8.8.8</span>
</pre></div>
</div>
</section>
</section>
<section id="cleaning-up-the-environment">
<h3>Cleaning up the environment<a class="headerlink" href="#cleaning-up-the-environment" title="Link to this heading"></a></h3>
<p>Each time a cluster is deployed, all the previously created resources are removed.
In case a user needs to remove the resources created by Kubeinit execute
from the project’s root folder:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">ansible-playbook \</span>
<span class="go">    -v --user root \</span>
<span class="go">    -e kubeinit_spec=okd-libvirt-3-2-1 \</span>
<span class="go">    -e kubeinit_stop_after_task=task-cleanup-hypervisors \</span>
<span class="go">    -i ./kubeinit/inventory.yml \</span>
<span class="go">    ./kubeinit/playbook.yml</span>
</pre></div>
</div>
<p>In this case the deployment will stop just after cleaning the
hypervisors resources. If its required to remove all the guests
in the hypervisors its also possible to add the following variable
<cite>-e kubeinit_libvirt_destroy_all_guests=True</cite></p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Welcome to KubeInit’s documentation!" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="architecture.html" class="btn btn-neutral float-right" title="Architecture" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright kubeinit contributors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>